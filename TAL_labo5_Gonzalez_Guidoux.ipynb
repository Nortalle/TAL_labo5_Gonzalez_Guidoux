{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cours TAL – Labo 5\n",
    "Nathan Gonzalez Montes et Vincent Guidoux\n",
    "\n",
    "## Exercice 1 - Tester et évaluer un modèle entraîné sur Google News\n",
    "\n",
    "### a) Installez la version 3.7.1 de gensim, la bibliothèque implémentant les outils pour travailler avec Word2Vec (pip install --upgrade gensim). Puis chargez le modèle word2vec pré-entraîné sur le corpus Google News en écrivant : w2v_model = gensim.downloader.load(\"word2vecgoogle-news-300\"), ce qui télécharge le fichier la première fois, et enfin en ne gardant que les vecteurs de mots, avec « w2v_vectors = w2v_model.wv » puis « del w2v_model »). Pour éviter ce téléchargement, on fournit le fichier sur une clé USB, et on peut le charger avec w2v_vectors = KeyedVectors.load_word2vec_format(path_to_file, binary=True). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Importation des librairies nécessaires"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "import nltk\n",
    "from gensim.test.utils import common_texts\n",
    "from gensim.models import Word2Vec\n",
    "from gensim.test.utils import get_tmpfile\n",
    "from gensim.models import KeyedVectors\n",
    "from gensim.test.utils import datapath"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Chargement du fichier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "w2v_vectors = KeyedVectors.load_word2vec_format(\"word2vec-google-news-300.gz\", binary=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Quelle place occupe le processus noyau en mémoire une fois les vecteurs de mots chargés ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4.6 Go"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b. Quelle est la dimension de l’espace vectoriel dans lequel les mots sont représentés ? Et quelle est la taille du vocabulaire du modèle ? Montrez 5 mots qui sont dans le vocabulaire et un qui ne l’est pas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Quelle est la dimension de l’espace vectoriel dans lequel les mots sont représentés ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3000000, 300)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v_vectors.vectors.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Et quelle est la taille du vocabulaire du modèle ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3000000"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(w2v_vectors.vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Montrez 5 mots qui sont dans le vocabulaire et un qui ne l’est pas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "victory is there\n",
      "defeat is there\n",
      "win is there\n",
      "loose is there\n",
      "champion is there\n",
      "Echallens is not there\n"
     ]
    }
   ],
   "source": [
    "words = [\"victory\", \"defeat\", \"win\", \"loose\", \"champion\", \"Echallens\"]\n",
    "\n",
    "for word in words:\n",
    "    if word in w2v_vectors.vocab:\n",
    "        print(\"{} is there\".format(word))\n",
    "    else:\n",
    "        print(\"{} is not there\".format(word))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### c. Comment peut-on mesurer la distance entre deux mots dans cet espace ? Calculez la distance entre les mots rabbit et carrot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.637\n"
     ]
    }
   ],
   "source": [
    "distance = w2v_vectors.distance(\"rabbit\", \"carrot\")\n",
    "print(\"{:.3f}\".format(distance))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.363\n"
     ]
    }
   ],
   "source": [
    "similarity = w2v_vectors.similarity(\"rabbit\", \"carrot\")\n",
    "print(\"{:.3f}\".format(similarity))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On peut observer que les méthodes distance et similarty son complémentaires. La somme des 2 valeurs est égale à 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### d. Testez le modèle de distance entre mots. Est-ce que des mots proches sémantiquement sont aussi proches dans l’espace vectoriel, et inversement ? Testez au moins cinq paires de mots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. 0.829\n",
      "2. 0.802\n",
      "3. 0.390\n",
      "4. 0.753\n",
      "5. 0.691\n",
      "6. 0.161\n",
      "7. 0.761\n",
      "8. 0.536\n",
      "9. 0.454\n"
     ]
    }
   ],
   "source": [
    "# On teste les similarity, ne devrait-il pas être les distances ? - Guidoux to Gonzalez\n",
    "\n",
    "similarity = w2v_vectors.similarity(\"victory\", \"triumph\") \n",
    "print(\"1. {:.3f}\".format(similarity))\n",
    "\n",
    "similarity = w2v_vectors.similarity(\"victory\", \"win\")\n",
    "print(\"2. {:.3f}\".format(similarity))\n",
    "\n",
    "similarity = w2v_vectors.similarity(\"victory\", \"champion\")\n",
    "print(\"3. {:.3f}\".format(similarity))\n",
    "\n",
    "similarity = w2v_vectors.similarity(\"victory\", \"victories\")\n",
    "print(\"4. {:.3f}\".format(similarity))\n",
    "\n",
    "similarity = w2v_vectors.similarity(\"victory\", \"defeat\")\n",
    "print(\"5. {:.3f}\".format(similarity))\n",
    "\n",
    "similarity = w2v_vectors.similarity(\"victory\", \"lose\")\n",
    "print(\"6. {:.3f}\".format(similarity))\n",
    "\n",
    "similarity = w2v_vectors.similarity(\"dog\", \"cat\")\n",
    "print(\"7. {:.3f}\".format(similarity))\n",
    "\n",
    "similarity = w2v_vectors.similarity(\"car\", \"bicycle\")\n",
    "print(\"8. {:.3f}\".format(similarity))\n",
    "\n",
    "similarity = w2v_vectors.similarity(\"Vaud\", \"Yverdon\")\n",
    "print(\"9. {:.3f}\".format(similarity))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On peut observer que les mots proches sémantiquemenet sont aussi proches dans l'espace et que la similarité est assez grande, comme par exemple **victory** and **triumph** (des synonymes), ou **victory** et **defeat** (des antonymes). \n",
    "\n",
    "Par contre, on peut aussi observer que des mots qui sont proches sémantiquement (**victory** et **champion**), sont assez éloignés quand on peut dire qu'une victoire mène à avoir un champion."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### e. Y a-t-il des cas ambigus, et pourquoi selon vous ? Par exemple, des mots opposés selon le sens sont-ils proches ou éloignés dans l’espace ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "On peut dire que oui en voyant les cas de l'exercise précédent avec par exemple, le fait que **victory** et **defeat** sont **similaires** à **69,1%** quand ce sont des mots opposés, mais vu qu'une victoire peut mener une défaite, la **distance** entre les deux mots ne devrait pas être très grande, ce qui serait plus logique comme résultat (vu que le complémentaire à cette similarité entre les mots est la distance qui les séparent). Tandis que la similarité entre **victory** et **lose** est très basse, car ce sont des mots opposés.\n",
    "\n",
    "Par rapport à la distance, si on compare **victory** et **champion**, ils sont assez distant si l'on peut considérer que si on a une victoire, il y a forcément un champion, et donc celui-ci devrait être plus proche du mot **victory**.\n",
    "\n",
    "On peut voir aussi que **dog** et **cat** son similaires entre eux quand ce sont des animaux différents."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### f. Que dire des mots ayant plusieurs sens ? Pouvez-vous donner 3 exemples de ce problème ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opposite (distance): 0.891\n",
      "Same (distance): 0.856\n",
      "Same (distance): 0.814 \n",
      "\n",
      "Opposite (similarity): 0.109\n",
      "Same (similarity): 0.144\n",
      "Same (similarity): 0.186 \n",
      "\n",
      "Opposite (distance): 0.508\n",
      "Same (distance): 0.597\n",
      "Same (distance): 0.885 \n",
      "\n",
      "Opposite (similarity): 0.492\n",
      "Same (similarity): 0.403\n",
      "Same (similarity): 0.115\n"
     ]
    }
   ],
   "source": [
    "distance = w2v_vectors.distance(\"present\", \"past\")\n",
    "print(\"Opposite (distance): {:.3f}\".format(distance))\n",
    "distance = w2v_vectors.distance(\"present\", \"now\")\n",
    "print(\"Same (distance): {:.3f}\".format(distance))\n",
    "distance = w2v_vectors.distance(\"present\", \"gift\")\n",
    "print(\"Same (distance): {:.3f}\".format(distance), \"\\n\")\n",
    "\n",
    "similarity = w2v_vectors.similarity(\"present\", \"past\")\n",
    "print(\"Opposite (similarity): {:.3f}\".format(similarity))\n",
    "similarity = w2v_vectors.similarity(\"present\", \"now\")\n",
    "print(\"Same (similarity): {:.3f}\".format(similarity))\n",
    "similarity = w2v_vectors.similarity(\"present\", \"gift\")\n",
    "print(\"Same (similarity): {:.3f}\".format(similarity), \"\\n\")\n",
    "\n",
    "distance = w2v_vectors.distance(\"right\", \"left\")\n",
    "print(\"Opposite (distance): {:.3f}\".format(distance))\n",
    "distance = w2v_vectors.distance(\"right\", \"correct\")\n",
    "print(\"Same (distance): {:.3f}\".format(distance))\n",
    "distance = w2v_vectors.distance(\"right\", \"law\")\n",
    "print(\"Same (distance): {:.3f}\".format(distance), \"\\n\")\n",
    "\n",
    "similarity = w2v_vectors.similarity(\"right\", \"left\")\n",
    "print(\"Opposite (similarity): {:.3f}\".format(similarity))\n",
    "similarity = w2v_vectors.similarity(\"right\", \"correct\")\n",
    "print(\"Same (similarity): {:.3f}\".format(similarity))\n",
    "similarity = w2v_vectors.similarity(\"right\", \"law\")\n",
    "print(\"Same (similarity): {:.3f}\".format(similarity))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Ici, on a utilisé **present** comme mot avec différent sens (comme **cadeau** et comme le **présent**), et on les a comparé, pour le **présent**, à un **synonyme et antonyme**, et pour **cadeau**, à un **synonyme**.\n",
    "\n",
    "On peut voir que étant un mot à plusieurs sens peut poser problème car même les synonymes sont distants entre eux et ne sont donc pas très similaires, mais avec l'antonyme, on a pareil, ce qui n'est pas très logique.\n",
    "\n",
    "Mais par exemple, pour le mot **right**, il y a des résultats partagés, avec son opposé **left**, qui est presque à **50-50%**, et un synonyme comme **correct** qui est un peu plus distant et moins similaire, donc à **60-40%**. Tandis que si on le compare à quelque chose qui est proche syntaxiquement comme **law** (les droits et la loi), la distance s'aggrandi et il n'y a quasi pas de similarité."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### g. En vous aidant de la documentation de Gensim sur KeyedVectors, mesurez de manière quantitative la performance du modèle sur le corpus WordSimilarity-353. Expliquez ce que signifient vos résultats."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "evaluate_word_pairs computes correlation of the model with human similarity judgments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from gensim.test.utils import datapath\n",
    "similarities = w2v_vectors.evaluate_word_pairs(datapath('wordsim353.tsv'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pearson correlation coefficient with 2-tailed p-value :  (0.6238773444802619, 1.7963251834702263e-39)\n",
      "\n",
      "\n",
      "Spearman rank-order correlation coefficient between the similarities from the dataset and the similarities produced by the model itself, with 2-tailed p-value :  SpearmanrResult(correlation=0.6589215888009288, pvalue=2.5346056459149263e-45)\n",
      "\n",
      "\n",
      "The ratio of pairs with unknown words :  0.0\n"
     ]
    }
   ],
   "source": [
    "print(\"Pearson correlation coefficient with 2-tailed p-value : \", similarities[0])\n",
    "print(\"\\n\")\n",
    "print(\"Spearman rank-order correlation coefficient between the similarities from the dataset and the similarities produced by the model itself, with 2-tailed p-value : \", similarities[1])\n",
    "print(\"\\n\")\n",
    "print(\"The ratio of pairs with unknown words : \", similarities[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### h. De même, en vous inspirant de la documentation, évaluez le modèle sur les données de test appelées questions-words.txt. Pouvez-vous expliquer ce que mesure ce test ? Les résultats du modèle sont-ils satisfaisants ? Commentez."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "evaluate_word_analogies compute performance of the model on an analogy test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "analogy_scores = w2v_vectors.evaluate_word_analogies(datapath('questions-words.txt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The overall evaluation score on the entire evaluation set :  0.7401448525607863\n",
      "\n",
      "\n",
      "Results broken down by each section of the evaluation set. Each dict contains the name of the section under the key ‘section’, and lists of correctly and incorrectly predicted 4-tuples of words under the keys ‘correct’ and ‘incorrect’. : \n",
      "\n",
      "\n",
      "section \"capital-common-countries\" : \n",
      "number of correct :  421\n",
      "number of incorrect :  85\n",
      "\n",
      "\n",
      "section \"capital-world\" : \n",
      "number of correct :  3552\n",
      "number of incorrect :  816\n",
      "\n",
      "\n",
      "section \"currency\" : \n",
      "number of correct :  230\n",
      "number of incorrect :  578\n",
      "\n",
      "\n",
      "section \"city-in-state\" : \n",
      "number of correct :  1779\n",
      "number of incorrect :  688\n",
      "\n",
      "\n",
      "section \"family\" : \n",
      "number of correct :  436\n",
      "number of incorrect :  70\n",
      "\n",
      "\n",
      "section \"gram1-adjective-to-adverb\" : \n",
      "number of correct :  290\n",
      "number of incorrect :  702\n",
      "\n",
      "\n",
      "section \"gram2-opposite\" : \n",
      "number of correct :  353\n",
      "number of incorrect :  459\n",
      "\n",
      "\n",
      "section \"gram3-comparative\" : \n",
      "number of correct :  1216\n",
      "number of incorrect :  116\n",
      "\n",
      "\n",
      "section \"gram4-superlative\" : \n",
      "number of correct :  987\n",
      "number of incorrect :  135\n",
      "\n",
      "\n",
      "section \"gram5-present-participle\" : \n",
      "number of correct :  829\n",
      "number of incorrect :  227\n",
      "\n",
      "\n",
      "section \"gram6-nationality-adjective\" : \n",
      "number of correct :  1442\n",
      "number of incorrect :  157\n",
      "\n",
      "\n",
      "section \"gram7-past-tense\" : \n",
      "number of correct :  1020\n",
      "number of incorrect :  540\n",
      "\n",
      "\n",
      "section \"gram8-plural\" : \n",
      "number of correct :  1159\n",
      "number of incorrect :  173\n",
      "\n",
      "\n",
      "section \"gram9-plural-verbs\" : \n",
      "number of correct :  593\n",
      "number of incorrect :  277\n",
      "\n",
      "\n",
      "section \"Total accuracy\" : \n",
      "number of correct :  14307\n",
      "number of incorrect :  5023\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"The overall evaluation score on the entire evaluation set : \", analogy_scores[0])\n",
    "print(\"\\n\")\n",
    "print(\"Results broken down by each section of the evaluation set. Each dict contains the name of the section under the key ‘section’, and lists of correctly and incorrectly predicted 4-tuples of words under the keys ‘correct’ and ‘incorrect’. : \")\n",
    "print(\"\\n\")\n",
    "\n",
    "for section in analogy_scores[1]:\n",
    "    print(\"section \\\"{section}\\\" : \".format(section=section[\"section\"]))\n",
    "    print(\"number of correct : \", len(section[\"correct\"]))\n",
    "    print(\"number of incorrect : \", len(section[\"incorrect\"]))\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercice 2 - Entraîner et tester deux nouveaux modèles à partir de corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a. Afin de pouvoir télécharger un corpus textuel par Gensim, exécutez la commande : import gensim.downloader. Puis récupérez le corpus des 108 premiers caractères de Wikipédia (en anglais) avec la commande : corpus = gensim.downloader.load('text8'). Combien de phrases et de mots possède ce corpus ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim.downloader\n",
    "corpus = gensim.downloader.load('text8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b. Entraînez un nouveau modèle word2vec sur ce nouveau corpus. Combien de temps prend l’entraînement et quelle est la taille (en Mo ou Go) du modèle word2vec résultant ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### c. Quelle dimension avez-vous choisi pour le plongement (embedding) de ce nouveau modèle ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### d. Testez quantitativement la qualité de ce nouveau modèle comme dans la partie 1 (points h et i). Ce modèle est-il meilleur que celui entraîné sur Google News ? Quelle serait la raison de la différence ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### e. Considérez maintenant le corpus quatre fois plus grand constitué de la concaténation du corpus text8 et des dépêches économiques de Reuters (corpus que nous vous mettons à disposition en ligne ou sur la clé USB comme wikipedia_augmented.dat). Utilisez ce nouveau corpus afin d’entraîner un nouveau modèle word2vec. Vous devez pour cela utiliser la fonction Text8Corpus() afin de charger et pré-traiter le texte du corpus (tokenization et segmentation en phrases, qui étaient déjà faites par la fonction load() du downloader). Combien de temps prend l’entraînement et quelle est la taille (en Mo) du modèle word2vec résultant ? Quelle est la dimension de l’embedding ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### f. Testez aussi ce modèle. Est-il meilleur que le précédent ? Pour quelle raison ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### g. Créez un nouveau fichier de test en augmentant questions-words.txt avec une catégorie de mots de votre choix (environ 20 items de test). Par exemple, à partir de {(eye, see), (ear, listen), (foot, walk)} on peut construire 6 items de test. Testez les trois modèles sur ces données, présentez et commentez vos résultats."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
