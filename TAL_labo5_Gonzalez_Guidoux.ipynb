{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cours TAL – Labo 5\n",
    "Nathan Gonzalez Montes et Vincent Guidoux\n",
    "\n",
    "## Exercice 1 - Tester et évaluer un modèle entraîné sur Google News\n",
    "\n",
    "### a) Installez la version 3.7.1 de gensim, la bibliothèque implémentant les outils pour travailler avec Word2Vec (pip install --upgrade gensim). Puis chargez le modèle word2vec pré-entraîné sur le corpus Google News en écrivant : w2v_model = gensim.downloader.load(\"word2vecgoogle-news-300\"), ce qui télécharge le fichier la première fois, et enfin en ne gardant que les vecteurs de mots, avec « w2v_vectors = w2v_model.wv » puis « del w2v_model »). Pour éviter ce téléchargement, on fournit le fichier sur une clé USB, et on peut le charger avec w2v_vectors = KeyedVectors.load_word2vec_format(path_to_file, binary=True). Quelle place occupe le processus noyau en mémoire une fois les vecteurs de mots chargés ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Importation des librairies nécessaires"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy\n",
    "import nltk\n",
    "from gensim.test.utils import common_texts\n",
    "from gensim.models import Word2Vec\n",
    "from gensim.test.utils import get_tmpfile\n",
    "from gensim.models import KeyedVectors\n",
    "from gensim.test.utils import datapath"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Chargement du fichier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<gensim.models.keyedvectors.Word2VecKeyedVectors at 0x235168cdef0>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v_vectors = KeyedVectors.load_word2vec_format(\"word2vec-google-news-300.gz\", binary=True)\n",
    "w2v_vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b. Quelle est la dimension de l’espace vectoriel dans lequel les mots sont représentés ? Et quelle est la taille du vocabulaire du modèle ? Montrez 5 mots qui sont dans le vocabulaire et un qui ne l’est pas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3000000, 300)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v_vectors.vectors.shape\n",
    "#len(w2v_vectors.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<gensim.models.keyedvectors.Vocab at 0x235169c0128>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v_vectors.vocab\n",
    "w2v_vectors.vocab[\"victory\"]\n",
    "# w2v_vectors.vocab[\"defeat\"]\n",
    "# w2v_vectors.vocab[\"win\"]\n",
    "# w2v_vectors.vocab[\"loose\"]\n",
    "# w2v_vectors.vocab[\"champion\"]\n",
    "# w2v_vectors.vocab[\"Echallens\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.32421875,  0.15722656,  0.1953125 , -0.24511719,  0.28125   ,\n",
       "       -0.30859375, -0.265625  , -0.5       ,  0.2578125 ,  0.42382812,\n",
       "       -0.02050781,  0.01525879, -0.00236511,  0.42773438, -0.12304688,\n",
       "        0.09277344,  0.1484375 ,  0.328125  ,  0.22070312, -0.14453125,\n",
       "        0.20410156,  0.31054688,  0.2578125 , -0.18847656,  0.09179688,\n",
       "       -0.25      , -0.26953125, -0.24023438, -0.15332031,  0.04956055,\n",
       "        0.15234375, -0.20800781,  0.11230469,  0.15527344,  0.15722656,\n",
       "        0.31054688,  0.04370117, -0.0222168 ,  0.09863281, -0.03662109,\n",
       "        0.08349609, -0.08740234,  0.24316406,  0.25390625, -0.04492188,\n",
       "       -0.10400391, -0.06591797, -0.02380371,  0.24414062,  0.00567627,\n",
       "        0.02001953,  0.41992188,  0.09765625,  0.20019531, -0.12255859,\n",
       "       -0.1015625 , -0.10791016, -0.26757812,  0.02697754, -0.2734375 ,\n",
       "        0.07177734, -0.0144043 , -0.10009766, -0.4140625 , -0.53125   ,\n",
       "        0.16113281,  0.1484375 ,  0.09814453,  0.26367188,  0.13964844,\n",
       "        0.15527344, -0.19921875, -0.09912109, -0.15039062,  0.04980469,\n",
       "       -0.3515625 ,  0.16699219, -0.12792969,  0.15625   ,  0.10546875,\n",
       "       -0.02587891, -0.04467773, -0.0612793 , -0.03710938, -0.00454712,\n",
       "        0.19921875, -0.05419922, -0.140625  ,  0.09667969,  0.08007812,\n",
       "       -0.05639648,  0.19335938, -0.046875  ,  0.02832031,  0.09570312,\n",
       "       -0.15332031,  0.02636719, -0.05664062, -0.17285156,  0.06494141,\n",
       "       -0.09179688,  0.16601562,  0.15039062, -0.10742188,  0.01599121,\n",
       "        0.01239014,  0.19433594, -0.37890625, -0.03710938, -0.04858398,\n",
       "        0.23535156, -0.06640625, -0.14550781, -0.02734375,  0.13183594,\n",
       "       -0.03881836, -0.09082031,  0.22363281, -0.140625  ,  0.03564453,\n",
       "       -0.19042969,  0.28125   ,  0.11572266, -0.30273438, -0.18359375,\n",
       "        0.0859375 , -0.20507812, -0.32421875,  0.06079102,  0.24511719,\n",
       "       -0.04980469,  0.12792969,  0.17578125, -0.0135498 , -0.14355469,\n",
       "        0.00315857,  0.21386719,  0.16015625, -0.33007812,  0.29882812,\n",
       "       -0.05932617, -0.24902344,  0.0559082 , -0.30273438, -0.11474609,\n",
       "        0.15234375, -0.27148438,  0.24609375, -0.19921875, -0.10205078,\n",
       "       -0.12597656,  0.05151367, -0.26953125, -0.38476562,  0.22363281,\n",
       "        0.0559082 , -0.08398438, -0.15136719,  0.03833008, -0.19921875,\n",
       "       -0.19824219, -0.00201416,  0.3203125 , -0.22949219, -0.09130859,\n",
       "       -0.23730469, -0.19824219, -0.16113281,  0.07568359,  0.34375   ,\n",
       "       -0.01855469, -0.12353516,  0.16308594, -0.08789062, -0.25976562,\n",
       "        0.10595703, -0.23242188, -0.01965332, -0.12890625,  0.01000977,\n",
       "       -0.42773438, -0.12890625,  0.36132812, -0.24023438, -0.00262451,\n",
       "        0.00096893, -0.05981445,  0.296875  ,  0.13867188,  0.12695312,\n",
       "        0.21289062,  0.03588867, -0.02929688,  0.02832031, -0.22851562,\n",
       "        0.03588867,  0.20019531,  0.203125  , -0.01965332, -0.01855469,\n",
       "       -0.08300781,  0.12451172,  0.26757812,  0.06494141,  0.02990723,\n",
       "       -0.08642578, -0.16308594,  0.078125  ,  0.11767578, -0.24902344,\n",
       "       -0.05834961,  0.13085938,  0.10058594,  0.21582031, -0.11181641,\n",
       "       -0.25976562, -0.11230469, -0.2421875 , -0.13476562, -0.02709961,\n",
       "       -0.00787354,  0.06640625,  0.21972656, -0.14257812,  0.03125   ,\n",
       "       -0.1640625 , -0.11279297,  0.17285156,  0.13085938,  0.12597656,\n",
       "       -0.01989746,  0.08691406, -0.32226562, -0.18261719,  0.03271484,\n",
       "       -0.09033203, -0.36523438,  0.05517578,  0.12451172, -0.02319336,\n",
       "        0.20800781, -0.07275391,  0.24121094, -0.12597656, -0.02587891,\n",
       "        0.09130859,  0.21582031, -0.07275391,  0.0168457 , -0.08105469,\n",
       "       -0.09130859, -0.03662109, -0.2578125 ,  0.01544189, -0.20898438,\n",
       "        0.19824219,  0.04858398, -0.18066406, -0.23828125, -0.02062988,\n",
       "        0.07617188,  0.06347656,  0.17285156, -0.01281738,  0.05786133,\n",
       "        0.06005859,  0.18945312,  0.02539062, -0.24316406, -0.27148438,\n",
       "        0.06079102,  0.01916504,  0.07666016, -0.12109375,  0.03344727,\n",
       "        0.01635742, -0.04321289, -0.05712891,  0.02587891,  0.0043335 ,\n",
       "        0.3125    ,  0.15136719, -0.02124023,  0.24023438, -0.29492188,\n",
       "       -0.2734375 ,  0.13476562,  0.15332031, -0.078125  , -0.24316406,\n",
       "       -0.06689453, -0.32421875, -0.15625   , -0.18457031, -0.17285156,\n",
       "       -0.05151367,  0.07666016, -0.20117188, -0.04248047,  0.06103516], dtype=float32)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v_vectors[\"victory\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### c. Comment peut-on mesurer la distance entre deux mots dans cet espace ? Calculez la distance entre les mots rabbit et carrot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.637\n"
     ]
    }
   ],
   "source": [
    "distance = w2v_vectors.distance(\"rabbit\", \"carrot\")\n",
    "print(\"{:.3f}\".format(distance))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.363\n"
     ]
    }
   ],
   "source": [
    "similarity = w2v_vectors.similarity(\"rabbit\", \"carrot\")\n",
    "print(\"{:.3f}\".format(similarity))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On peut observer que les méthodes distance et similarty son complémentaires. La somme des 2 valeurs est égale à 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### d. Testez le modèle de distance entre mots. Est-ce que des mots proches sémantiquement sont aussi proches dans l’espace vectoriel, et inversement ? Testez au moins cinq paires de mots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. 0.829\n",
      "2. 0.802\n",
      "3. 0.390\n",
      "4. 0.753\n",
      "5. 0.691\n",
      "6. 0.161\n",
      "7. 0.761\n",
      "8. 0.536\n",
      "9. 0.454\n"
     ]
    }
   ],
   "source": [
    "similarity = w2v_vectors.similarity(\"victory\", \"triumph\")\n",
    "print(\"1. {:.3f}\".format(similarity))\n",
    "\n",
    "similarity = w2v_vectors.similarity(\"victory\", \"win\")\n",
    "print(\"2. {:.3f}\".format(similarity))\n",
    "\n",
    "similarity = w2v_vectors.similarity(\"victory\", \"champion\")\n",
    "print(\"3. {:.3f}\".format(similarity))\n",
    "\n",
    "similarity = w2v_vectors.similarity(\"victory\", \"victories\")\n",
    "print(\"4. {:.3f}\".format(similarity))\n",
    "\n",
    "similarity = w2v_vectors.similarity(\"victory\", \"defeat\")\n",
    "print(\"5. {:.3f}\".format(similarity))\n",
    "\n",
    "similarity = w2v_vectors.similarity(\"victory\", \"lose\")\n",
    "print(\"6. {:.3f}\".format(similarity))\n",
    "\n",
    "similarity = w2v_vectors.similarity(\"dog\", \"cat\")\n",
    "print(\"7. {:.3f}\".format(similarity))\n",
    "\n",
    "similarity = w2v_vectors.similarity(\"car\", \"bicycle\")\n",
    "print(\"8. {:.3f}\".format(similarity))\n",
    "\n",
    "similarity = w2v_vectors.similarity(\"Vaud\", \"Yverdon\")\n",
    "print(\"9. {:.3f}\".format(similarity))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On peut observer que les mots proches sémantiquemenet sont aussi proches dans l'espace et que la similarité est assez grande, comme par exemple **victory** and **triumph** (des synonymes), ou **victory** et **defeat** (des antonymes). \n",
    "\n",
    "Par contre, on peut aussi observer que des mots qui sont proches sémantiquement (**victory** et **champion**), sont assez éloignés quand on peut dire qu'une victoire mène à avoir un champion."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### e. Y a-t-il des cas ambigus, et pourquoi selon vous ? Par exemple, des mots opposés selon le sens sont-ils proches ou éloignés dans l’espace ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "On peut dire que oui en voyant les cas de l'exercise précédent avec par exemple, le fait que **victory** et **defeat** sont **similaires** à **69,1%** quand ce sont des mots opposés, mais vu qu'une victoire peut mener une défaite, la **distance** entre les deux mots ne devrait pas être très grande, ce qui serait plus logique comme résultat (vu que le complémentaire à cette similarité entre les mots est la distance qui les séparent). Tandis que la similarité entre **victory** et **lose** est très basse, car ce sont des mots opposés.\n",
    "\n",
    "Par rapport à la distance, si on compare **victory** et **champion**, ils sont assez distant si l'on peut considérer que si on a une victoire, il y a forcément un champion, et donc celui-ci devrait être plus proche du mot **victory**.\n",
    "\n",
    "On peut voir aussi que **dog** et **cat** son similaires entre eux quand ce sont des animaux différents."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### f. Que dire des mots ayant plusieurs sens ? Pouvez-vous donner 3 exemples de ce problème ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opposite (distance): 0.891\n",
      "Same (distance): 0.856\n",
      "Same (distance): 0.814 \n",
      "\n",
      "Opposite (similarity): 0.109\n",
      "Same (similarity): 0.109\n",
      "Same (similarity): 0.186 \n",
      "\n",
      "Opposite (distance): 0.508\n",
      "Same (distance): 0.597\n",
      "Same (distance): 0.885 \n",
      "\n",
      "Opposite (similarity): 0.492\n",
      "Same (similarity): 0.403\n",
      "Same (similarity): 0.115\n"
     ]
    }
   ],
   "source": [
    "distance = w2v_vectors.distance(\"present\", \"past\")\n",
    "print(\"Opposite (distance): {:.3f}\".format(distance))\n",
    "distance = w2v_vectors.distance(\"present\", \"now\")\n",
    "print(\"Same (distance): {:.3f}\".format(distance))\n",
    "distance = w2v_vectors.distance(\"present\", \"gift\")\n",
    "print(\"Same (distance): {:.3f}\".format(distance), \"\\n\")\n",
    "\n",
    "similarity = w2v_vectors.similarity(\"present\", \"past\")\n",
    "print(\"Opposite (similarity): {:.3f}\".format(similarity))\n",
    "similarity = w2v_vectors.similarity(\"present\", \"past\")\n",
    "print(\"Same (similarity): {:.3f}\".format(similarity))\n",
    "similarity = w2v_vectors.similarity(\"present\", \"gift\")\n",
    "print(\"Same (similarity): {:.3f}\".format(similarity), \"\\n\")\n",
    "\n",
    "distance = w2v_vectors.distance(\"right\", \"left\")\n",
    "print(\"Opposite (distance): {:.3f}\".format(distance))\n",
    "distance = w2v_vectors.distance(\"right\", \"correct\")\n",
    "print(\"Same (distance): {:.3f}\".format(distance))\n",
    "distance = w2v_vectors.distance(\"right\", \"law\")\n",
    "print(\"Same (distance): {:.3f}\".format(distance), \"\\n\")\n",
    "\n",
    "similarity = w2v_vectors.similarity(\"right\", \"left\")\n",
    "print(\"Opposite (similarity): {:.3f}\".format(similarity))\n",
    "similarity = w2v_vectors.similarity(\"right\", \"correct\")\n",
    "print(\"Same (similarity): {:.3f}\".format(similarity))\n",
    "similarity = w2v_vectors.similarity(\"right\", \"law\")\n",
    "print(\"Same (similarity): {:.3f}\".format(similarity))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Ici, on a utilisé **present** comme mot avec différent sens (comme **cadeau** et comme le **présent**), et on les a comparé, pour le **présent**, à un **synonyme et antonyme**, et pour **cadeau**, à un **synonyme**.\n",
    "\n",
    "On peut voir que étant un mot à plusieurs sens peut poser problème car même les synonymes sont distants entre eux et ne sont donc pas très similaires, mais avec l'antonyme, on a pareil, ce qui n'est pas très logique.\n",
    "\n",
    "Mais par exemple, pour le mot **right**, il y a des résultats partagés, avec son opposé **left**, qui est presque à **50-50%**, et un synonyme comme **correct** qui est un peu plus distant et moins similaire, donc à **60-40%**. Tandis que si on le compare à quelque chose qui est proche syntaxiquement comme **law** (les droits et la loi), la distance s'aggrandi et il n'y a quasi pas de similarité."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### g. En vous aidant de la documentation de Gensim sur KeyedVectors, mesurez de manière quantitative la performance du modèle sur le corpus WordSimilarity-353. Expliquez ce que signifient vos résultats."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from gensim.test.utils import datapath\n",
    "similarities = model.wv.evaluate_word_pairs(datapath('wordsim353.tsv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### h. De même, en vous inspirant de la documentation, évaluez le modèle sur les données de test appelées questions-words.txt. Pouvez-vous expliquer ce que mesure ce test ? Les résultats du modèle sont-ils satisfaisants ? Commentez."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercice 2 - Entraîner et tester deux nouveaux modèles à partir de corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a. Afin de pouvoir télécharger un corpus textuel par Gensim, exécutez la commande : import gensim.downloader. Puis récupérez le corpus des 108 premiers caractères de Wikipédia (en anglais) avec la commande : corpus = gensim.downloader.load('text8'). Combien de phrases et de mots possède ce corpus ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<text8.Dataset at 0x20d5abe5b70>"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gensim.downloader\n",
    "corpus = gensim.downloader.load('text8')\n",
    "corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b. Entraînez un nouveau modèle word2vec sur ce nouveau corpus. Combien de temps prend l’entraînement et quelle est la taille (en Mo ou Go) du modèle word2vec résultant ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### c. Quelle dimension avez-vous choisi pour le plongement (embedding) de ce nouveau modèle ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### d. Testez quantitativement la qualité de ce nouveau modèle comme dans la partie 1 (points h et i). Ce modèle est-il meilleur que celui entraîné sur Google News ? Quelle serait la raison de la différence ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### e. Considérez maintenant le corpus quatre fois plus grand constitué de la concaténation du corpus text8 et des dépêches économiques de Reuters (corpus que nous vous mettons à disposition en ligne ou sur la clé USB comme wikipedia_augmented.dat). Utilisez ce nouveau corpus afin d’entraîner un nouveau modèle word2vec. Vous devez pour cela utiliser la fonction Text8Corpus() afin de charger et pré-traiter le texte du corpus (tokenization et segmentation en phrases, qui étaient déjà faites par la fonction load() du downloader). Combien de temps prend l’entraînement et quelle est la taille (en Mo) du modèle word2vec résultant ? Quelle est la dimension de l’embedding ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### f. Testez aussi ce modèle. Est-il meilleur que le précédent ? Pour quelle raison ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### g. Créez un nouveau fichier de test en augmentant questions-words.txt avec une catégorie de mots de votre choix (environ 20 items de test). Par exemple, à partir de {(eye, see), (ear, listen), (foot, walk)} on peut construire 6 items de test. Testez les trois modèles sur ces données, présentez et commentez vos résultats."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
